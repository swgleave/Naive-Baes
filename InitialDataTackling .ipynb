{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>idx</th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>target_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98221616</td>\n",
       "      <td>4976</td>\n",
       "      <td>$ARNA APD334 for Amyotrophic Lateral Sclerosis...</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82321187</td>\n",
       "      <td>9839</td>\n",
       "      <td>$OCLR Noob investor that i am, put a 7.38 stop...</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>stop loss</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103328840</td>\n",
       "      <td>1455</td>\n",
       "      <td>$ES_F $SPY Bias-2 bearish and the DLT-1 DRR ar...</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104840294</td>\n",
       "      <td>1111</td>\n",
       "      <td>$TMUS its acquisition of Layer3 TV The purchas...</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69935467</td>\n",
       "      <td>2373</td>\n",
       "      <td>$TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>relative</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69935467</td>\n",
       "      <td>2373</td>\n",
       "      <td>$TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69935467</td>\n",
       "      <td>2373</td>\n",
       "      <td>$TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>forecast</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94249158</td>\n",
       "      <td>1372</td>\n",
       "      <td>$SEED L2 Capital deal is real savvy. It takes ...</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>date</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100979260</td>\n",
       "      <td>505</td>\n",
       "      <td>$BTE $BTE.CA $MEG.CA $CPG $CPG.CA $CJ.CA - 4th...</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>date</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100775772</td>\n",
       "      <td>1210</td>\n",
       "      <td>$WRN My fav $WRN pattern on my watchlist for 1...</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>date</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   idx                                              tweet  \\\n",
       "0   98221616  4976  $ARNA APD334 for Amyotrophic Lateral Sclerosis...   \n",
       "1   82321187  9839  $OCLR Noob investor that i am, put a 7.38 stop...   \n",
       "2  103328840  1455  $ES_F $SPY Bias-2 bearish and the DLT-1 DRR ar...   \n",
       "3  104840294  1111  $TMUS its acquisition of Layer3 TV The purchas...   \n",
       "4   69935467  2373  $TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...   \n",
       "5   69935467  2373  $TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...   \n",
       "6   69935467  2373  $TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...   \n",
       "7   94249158  1372  $SEED L2 Capital deal is real savvy. It takes ...   \n",
       "8  100979260   505  $BTE $BTE.CA $MEG.CA $CPG $CPG.CA $CJ.CA - 4th...   \n",
       "9  100775772  1210  $WRN My fav $WRN pattern on my watchlist for 1...   \n",
       "\n",
       "         category     subcategory target_num  \n",
       "0  Product Number  Product Number        334  \n",
       "1        Monetary       stop loss       7.38  \n",
       "2  Product Number  Product Number          1  \n",
       "3  Product Number  Product Number          5  \n",
       "4      Percentage        relative         14  \n",
       "5        Quantity        Quantity          4  \n",
       "6        Monetary        forecast          5  \n",
       "7        Temporal            date         33  \n",
       "8        Temporal            date          4  \n",
       "9        Temporal            date         11  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'finnum\\train.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in fastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load('fastText1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing tweets by lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lower'] = [x.lower() for x in df.tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    $arna apd334 for amyotrophic lateral sclerosis...\n",
       "1    $oclr noob investor that i am, put a 7.38 stop...\n",
       "2    $es_f $spy bias-2 bearish and the dlt-1 drr ar...\n",
       "3    $tmus its acquisition of layer3 tv the purchas...\n",
       "4    $twtr ^buy  $wstl 68c up 14%  4 time avg vol. ...\n",
       "Name: lower, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lower'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing target with <num\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def flagNum(x):\n",
    "    text = x.lower\n",
    "    outNum = str(x.target_num)\n",
    "    text_out = re.sub(r'(?<=\\D)'+outNum+'(?=\\D)', ' <num> ', text)\n",
    "    #text_out = text.replace('\\D('+outNum+')\\D', ' <num> ')\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying to training, making this into a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mod'] = df.apply(lambda x: flagNum(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    $arna apd <num>  for amyotrophic lateral scler...\n",
       "1    $oclr noob investor that i am, put a  <num>  s...\n",
       "2    $es_f $spy bias-2 bearish and the dlt- <num>  ...\n",
       "3    $tmus its acquisition of layer3 tv the purchas...\n",
       "4    $twtr ^buy  $wstl 68c up  <num> %  4 time avg ...\n",
       "Name: mod, dtype: object"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mod'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    $arna apd334 for amyotrophic lateral sclerosis...\n",
       "1    $oclr noob investor that i am, put a 7.38 stop...\n",
       "2    $es_f $spy bias-2 bearish and the dlt-1 drr ar...\n",
       "3    $tmus its acquisition of layer3 tv the purchas...\n",
       "4    $twtr ^buy  $wstl 68c up 14%  4 time avg vol. ...\n",
       "Name: lower, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lower.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out numbers and words less than 3 characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def textPuncandNum(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    text = text.split()\n",
    "    text = [word for word in text if len(word.translate(table))>2]\n",
    "    return ' '.join(text)\n",
    "stripped = [textPuncandNum(text) for text in df['mod']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating list of unique words from this processed text, excluding <num\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13126"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low = list(stripped)\n",
    "low = ' '.join(low)\n",
    "low = list(set(low.split()))\n",
    "low.remove('<num>')\n",
    "len(low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gentlemen,',\n",
       " 'closures',\n",
       " 'backing',\n",
       " '(low',\n",
       " 'pipe',\n",
       " 'behavior',\n",
       " 'ago..',\n",
       " 'questions.',\n",
       " 'pr/er',\n",
       " 'lot',\n",
       " 'gave',\n",
       " 'char',\n",
       " 'hurts,',\n",
       " 'rush',\n",
       " '$mkc.',\n",
       " '(but',\n",
       " '%.....almost',\n",
       " 'pre-earnings',\n",
       " 'stop.',\n",
       " 'wage',\n",
       " 'gimme',\n",
       " 'balance',\n",
       " 'standby.over',\n",
       " 'nhl,',\n",
       " 'bottom.',\n",
       " '$once',\n",
       " 'driving',\n",
       " 'comml',\n",
       " '&quot;no',\n",
       " 'day..hmm.',\n",
       " 'employment,',\n",
       " 'parade',\n",
       " 'action',\n",
       " 'nest,',\n",
       " 'updated',\n",
       " 'order?',\n",
       " '$rox',\n",
       " 'sma.',\n",
       " 'million-dollars.html',\n",
       " 'upside',\n",
       " 'brands/costs',\n",
       " 'collectively',\n",
       " '@nautica',\n",
       " 'steal!',\n",
       " '$covalbtc',\n",
       " 'crossover',\n",
       " 'snatched',\n",
       " 'adding',\n",
       " 'core',\n",
       " 'fidelity',\n",
       " 'pharmas',\n",
       " 'down!!!',\n",
       " 'proof',\n",
       " 'neo',\n",
       " 'yet-',\n",
       " 'position?',\n",
       " 'viral',\n",
       " 'longer.',\n",
       " '$drio',\n",
       " 'purchase!!',\n",
       " '$tops',\n",
       " 'wells',\n",
       " 'https://t.co/wfeoisai',\n",
       " 'rating.',\n",
       " 'direction',\n",
       " 'value=$mm,',\n",
       " 'guidance',\n",
       " 'day,',\n",
       " 'couple',\n",
       " 'possible',\n",
       " '$cafd',\n",
       " 'http://ibankcoin.com/raul////breaking-blog-silence-to-clarify-my-bullish-beliefs/',\n",
       " '$abio',\n",
       " 'arriving',\n",
       " 'thanksgiving.',\n",
       " '@april',\n",
       " '$idra',\n",
       " 'bringin',\n",
       " 'hft',\n",
       " 'thereafter,',\n",
       " '@benstein',\n",
       " '@gpheonix',\n",
       " 'tight',\n",
       " 'long-term',\n",
       " 'https://www.cnbc.com////billionaire-ron-baron-says-any-patient-investor-can-turn--dollars-a-year-into-nearly',\n",
       " 'loved',\n",
       " 'afford',\n",
       " 'childers,',\n",
       " 'https://youtu.be/twoipadz',\n",
       " '$race',\n",
       " 'h......gold',\n",
       " 'downs',\n",
       " 'comparing',\n",
       " '$surrf,',\n",
       " 'trxc',\n",
       " 'eod,',\n",
       " 'speculation',\n",
       " 'oled.',\n",
       " 'profits',\n",
       " '$upl',\n",
       " 'binance',\n",
       " '$alt',\n",
       " '$cvs,',\n",
       " 'panl/oled',\n",
       " 'take?',\n",
       " '$rjf',\n",
       " 'terribly',\n",
       " 'vera',\n",
       " 'spot-',\n",
       " 'cobalt',\n",
       " 'chardan',\n",
       " 'mnk',\n",
       " 'kong',\n",
       " 'taking.',\n",
       " 'down....',\n",
       " 'transform',\n",
       " 'powerpacks',\n",
       " 'bought,',\n",
       " 'citizen',\n",
       " 'charge',\n",
       " '@gumamela',\n",
       " 'crashed',\n",
       " 'irs',\n",
       " 'attendees',\n",
       " 'averaged',\n",
       " 'ether,',\n",
       " 'kfg',\n",
       " 'afterall.',\n",
       " '$ras',\n",
       " '@unitedtraders',\n",
       " 'immu&gt;',\n",
       " 'higher,on',\n",
       " 'continues',\n",
       " '$nfx',\n",
       " 'vxx',\n",
       " 'producers.',\n",
       " '$rwlk',\n",
       " 'pst',\n",
       " 'maintained',\n",
       " 'investments',\n",
       " '$pgh',\n",
       " 'fack',\n",
       " '$spg',\n",
       " 'swings.',\n",
       " 'ohh',\n",
       " 'srax.',\n",
       " 'series',\n",
       " 'users.',\n",
       " 'too.',\n",
       " 'loan',\n",
       " 'social',\n",
       " 'math',\n",
       " 'haha',\n",
       " 'price!!',\n",
       " 's,than',\n",
       " 'up&quot;',\n",
       " 'joint',\n",
       " 'burr',\n",
       " 'worries',\n",
       " 'corp',\n",
       " '$snoaw',\n",
       " 'news?!',\n",
       " '$isig',\n",
       " '$tqqq*',\n",
       " 'recognition',\n",
       " 'natgas',\n",
       " 'industrials',\n",
       " 'opened',\n",
       " 'amount.',\n",
       " 'ops',\n",
       " 'purposes',\n",
       " 'capped',\n",
       " 'disruptions:',\n",
       " 'right',\n",
       " 'year-old-company-at-a--year-low',\n",
       " 'left',\n",
       " 'price..',\n",
       " 'assure',\n",
       " 'fabry',\n",
       " '#btc',\n",
       " 'mgti',\n",
       " '$dax',\n",
       " 'content',\n",
       " 'woods.',\n",
       " 'spike',\n",
       " 'total=',\n",
       " 'nyse',\n",
       " 'beaten',\n",
       " '&quot;eve',\n",
       " 'frame:',\n",
       " 'breakouts',\n",
       " 'acres',\n",
       " 'acquire',\n",
       " '#tothemoon',\n",
       " 'pension.',\n",
       " 'https://youtu.be/mwbswifoae',\n",
       " 'behind',\n",
       " 'wife',\n",
       " '#vertex',\n",
       " 'dexay.',\n",
       " 'congress.',\n",
       " '$tho.ca',\n",
       " 'department',\n",
       " 'others?',\n",
       " '&quot;',\n",
       " '$crvl',\n",
       " 'ontario',\n",
       " 'next.',\n",
       " '$lxrx',\n",
       " 'summarizing',\n",
       " 'violent',\n",
       " 'https://www.als.net/docs/uploads/why_might_gilenya_be_helpful_for_als.pdf',\n",
       " 'priced',\n",
       " 'blockchain.',\n",
       " 'google',\n",
       " '$odfl',\n",
       " 'gtc.',\n",
       " 'buffett',\n",
       " 'taking',\n",
       " 'toshiba',\n",
       " 'western',\n",
       " 'otherwise',\n",
       " '$trgp',\n",
       " '$blue',\n",
       " 'plx',\n",
       " 'compiling',\n",
       " 'noobs',\n",
       " 'safe',\n",
       " 'scrolling',\n",
       " '$vii',\n",
       " 'prospectus',\n",
       " 'dimon?',\n",
       " 'bulling',\n",
       " 'irma',\n",
       " 'now...',\n",
       " '$abt',\n",
       " 'seconds',\n",
       " '$rdus',\n",
       " 'sale.',\n",
       " 'wud',\n",
       " 'premium',\n",
       " 'zuma',\n",
       " 'www.robinhoodstrategy.com',\n",
       " '$watt',\n",
       " '$achc',\n",
       " '$tops,',\n",
       " 'outpacing',\n",
       " '#homebuilders',\n",
       " 'ahhhhh,',\n",
       " 'nor',\n",
       " 'conference?',\n",
       " 'truly',\n",
       " 'wait.',\n",
       " 'devices',\n",
       " 'min,',\n",
       " 'reports',\n",
       " '$vrtx',\n",
       " 'summary',\n",
       " 'drop/dump',\n",
       " 'spot',\n",
       " 'opposite',\n",
       " 'vwap,',\n",
       " '@thewolferny',\n",
       " 'too!',\n",
       " '$opht',\n",
       " 'morning....k',\n",
       " '#etfs',\n",
       " 'correlate',\n",
       " 'page',\n",
       " 'baron',\n",
       " 'sore....',\n",
       " 'coming,',\n",
       " '$srpt',\n",
       " 'winner',\n",
       " 'exploration',\n",
       " 'sooner',\n",
       " '$lea.',\n",
       " 'ore',\n",
       " 'massive...',\n",
       " 'https://finance.yahoo.com/news',\n",
       " '$bts.x',\n",
       " '$cpk',\n",
       " 'http://media.corporate-ir.net/media_files/irol///ccbc_presentation_..pdf',\n",
       " '$znga',\n",
       " 'k-cup',\n",
       " 'center',\n",
       " 'https://firstoinvest.com/melinta-therapeutics-case-study/',\n",
       " 'hinted',\n",
       " '&quot;healthcare',\n",
       " 'shopify',\n",
       " 'week',\n",
       " 'lonely',\n",
       " 'allows',\n",
       " 'buoyancy',\n",
       " '$pgr',\n",
       " 'top)',\n",
       " 'date:',\n",
       " 'understand',\n",
       " 'https://investoralmanac.com////boyar-value-group',\n",
       " 'lol)',\n",
       " 'averages',\n",
       " 'licking',\n",
       " '$petz',\n",
       " 'app.',\n",
       " 'opy,',\n",
       " 'hit,',\n",
       " 'threat',\n",
       " 'greatest',\n",
       " '&quot;always',\n",
       " 'http://www.businesswire.com/news/home//en',\n",
       " 'sell..',\n",
       " 'philip',\n",
       " '&quot;hold&quot;',\n",
       " 'easy..',\n",
       " '&quot;alibaba',\n",
       " 'rebounded',\n",
       " 'tdy',\n",
       " 'selling.',\n",
       " 'leaking',\n",
       " '$arlz.',\n",
       " '$.cents',\n",
       " 'moat',\n",
       " 'useless/repeated',\n",
       " '$trvg',\n",
       " 'serving',\n",
       " 'o&amp;g',\n",
       " 'prescriptions.',\n",
       " 'boost!!!!',\n",
       " 'prev',\n",
       " '$salt',\n",
       " 'deja',\n",
       " 'provide',\n",
       " '$aimt',\n",
       " 'makers',\n",
       " '@towman',\n",
       " 'hmm',\n",
       " 'sidelines',\n",
       " 'restated',\n",
       " 'sidoti',\n",
       " 'net,',\n",
       " '...seems',\n",
       " 'transportation/automotive,',\n",
       " 'knee',\n",
       " 'speak',\n",
       " '#uranium',\n",
       " 'sites',\n",
       " 'chasers',\n",
       " '$dxlg',\n",
       " 'order,',\n",
       " 'involvemt',\n",
       " 'savvy',\n",
       " 'oil?',\n",
       " 'windfall',\n",
       " 'maneuver',\n",
       " '$esea',\n",
       " '$pphm',\n",
       " 'expect',\n",
       " 'secrets',\n",
       " 'promo',\n",
       " 'mess.',\n",
       " 'prepare',\n",
       " 'tomorrow!!',\n",
       " 'loonie',\n",
       " 'late.',\n",
       " 'meaningless..',\n",
       " 'trash!',\n",
       " 'solar',\n",
       " 'indicator/overlay',\n",
       " 'wed.',\n",
       " '$alks',\n",
       " 'tnbc',\n",
       " 'try',\n",
       " 'boredom.',\n",
       " 'points,',\n",
       " 'pants',\n",
       " '$mzor',\n",
       " 'majority',\n",
       " 'lolol',\n",
       " 'friend....let&#;s',\n",
       " 'edma',\n",
       " 'summary,',\n",
       " 'tie.',\n",
       " 'between',\n",
       " '$rsge',\n",
       " 'issued.',\n",
       " 'canna',\n",
       " '$cgix',\n",
       " '$akg',\n",
       " 'risinger',\n",
       " '$cpah',\n",
       " 'drugs',\n",
       " 'tmrw',\n",
       " 'expiration',\n",
       " '$ipos',\n",
       " 'ipos...',\n",
       " '//fda-reverses-decision-allowing-amicus-to-file-for-rare-disease-drug/#bfcb',\n",
       " 'stk',\n",
       " 'site.',\n",
       " '(ex-csco)',\n",
       " 'revenue.',\n",
       " 'lead.',\n",
       " 'bull,',\n",
       " '$nq&#;s',\n",
       " 'explodes',\n",
       " 'change',\n",
       " 'hotel',\n",
       " 'winners',\n",
       " 'stronger,',\n",
       " 'sums',\n",
       " 'investors,',\n",
       " 'corporation',\n",
       " '@frteamster',\n",
       " 'cata',\n",
       " 'runs..?',\n",
       " '$syn',\n",
       " 'goof',\n",
       " 'analyst&#;s',\n",
       " 'delayed',\n",
       " 'needham.',\n",
       " 'reputable!',\n",
       " 'exposure',\n",
       " '&quot;i',\n",
       " 'hitched',\n",
       " '$cris',\n",
       " 'tsl,)',\n",
       " 'october&#;s',\n",
       " 'impaired',\n",
       " 'catches',\n",
       " 'support',\n",
       " 'license',\n",
       " 'iphone',\n",
       " '$ngvc',\n",
       " 'fined',\n",
       " '$rexx',\n",
       " 'play...%',\n",
       " 'begins',\n",
       " 'easing',\n",
       " '$scs',\n",
       " 'tick',\n",
       " 'strategic',\n",
       " 'fueling',\n",
       " 'btl',\n",
       " 'obvsly',\n",
       " 'suicide',\n",
       " 'temasek',\n",
       " 'reported',\n",
       " 'imbalance:',\n",
       " 'december',\n",
       " 'xbox',\n",
       " '$mrk',\n",
       " 'ibd',\n",
       " 'ecommerce',\n",
       " 'doubted',\n",
       " 'deduc&gt;',\n",
       " 'roadster',\n",
       " 'daily....',\n",
       " 'wiped',\n",
       " 'babe....give',\n",
       " 'insane',\n",
       " 'indicated.***',\n",
       " 'hot',\n",
       " 'starter.',\n",
       " '@yen_hee',\n",
       " 'stmicroelectronics',\n",
       " 'clueless',\n",
       " 'orange.',\n",
       " 'found-',\n",
       " 'enph',\n",
       " 'pigs',\n",
       " '$wft',\n",
       " 'https://www.tradingview.com/x/bhttzc/',\n",
       " 'kids',\n",
       " '$pzza',\n",
       " 'https://www.youtube.com/watch?v=mvrzeopwlwu',\n",
       " 'own.',\n",
       " '$cacc',\n",
       " 'tomorrow,',\n",
       " 'zone!',\n",
       " '$oild',\n",
       " 'wrecked',\n",
       " 'unblinding',\n",
       " 'exit',\n",
       " '$smh',\n",
       " '$bpmx.',\n",
       " 'conflict',\n",
       " 'blast,',\n",
       " 'tuttifrutti',\n",
       " 'leg-up',\n",
       " 'sound',\n",
       " 'nhod-move',\n",
       " 'banking!',\n",
       " 'http://stks.co/dmv',\n",
       " 'harvesting?',\n",
       " 'tbv,',\n",
       " 'powder..come',\n",
       " '$wlb',\n",
       " 'january',\n",
       " '@stockcat',\n",
       " 'macys',\n",
       " '$tep',\n",
       " 'win!!',\n",
       " 'holy',\n",
       " 'http://www.natgasweather.com/',\n",
       " '$quad',\n",
       " '$insy',\n",
       " 'her.',\n",
       " 'ater',\n",
       " 'seen,',\n",
       " '$voya.',\n",
       " 'floater',\n",
       " 'nascent',\n",
       " '$hive',\n",
       " 'surprised',\n",
       " '$ulta',\n",
       " 'vehicles',\n",
       " 'rember',\n",
       " '$egle',\n",
       " 'way!',\n",
       " '$sfun',\n",
       " 'spring.',\n",
       " 'vina',\n",
       " 'agreements,',\n",
       " 'sit',\n",
       " 'committed',\n",
       " '@jamyjar',\n",
       " 'racks',\n",
       " '$hcn',\n",
       " '$axon',\n",
       " 'table,',\n",
       " 'area.i',\n",
       " 'record:',\n",
       " 'tcehy',\n",
       " 'aluminum',\n",
       " '$jpnl',\n",
       " 'remained',\n",
       " '$meg.ca',\n",
       " 'admits',\n",
       " 'settled',\n",
       " 'exelent',\n",
       " 'msft,',\n",
       " '$mil',\n",
       " 'might',\n",
       " 'irritates',\n",
       " 'roku',\n",
       " 'performance',\n",
       " '@husker',\n",
       " '$bsx',\n",
       " 'http://www.marketwatch',\n",
       " 'every',\n",
       " 'initiate',\n",
       " 'wishing',\n",
       " '$bas',\n",
       " 'candle.',\n",
       " 'way.',\n",
       " '$dzz',\n",
       " 'backers',\n",
       " '$kone',\n",
       " 'over,',\n",
       " '$uco',\n",
       " 'remission.',\n",
       " 'collusion',\n",
       " 'true,',\n",
       " 'baby.',\n",
       " 'calls/shares,',\n",
       " 'industrial',\n",
       " 'sympathy',\n",
       " 'passionate-some',\n",
       " 'gobose.mavyret',\n",
       " 'trailing',\n",
       " 'wer',\n",
       " 'booyah',\n",
       " 'propaganda',\n",
       " 'https://seekingalpha.com/article/-madalena-energys-mdlnf-ceo-jose-penafiel-q--results-earnings-call-transcript?source=tweet',\n",
       " 'accurately',\n",
       " 'bit',\n",
       " 'sting',\n",
       " '$nee',\n",
       " 'primary',\n",
       " 'accounts.',\n",
       " '$cmcsa.',\n",
       " 'completed',\n",
       " '$ctso',\n",
       " 'seem',\n",
       " 'positons)',\n",
       " 'actually',\n",
       " 'overdone,',\n",
       " '//gbpaud-nearing',\n",
       " 'palladium',\n",
       " 'medicine.',\n",
       " 'directors',\n",
       " 'down!!!!',\n",
       " 'bears',\n",
       " '$gsl',\n",
       " 'banger',\n",
       " '$rmp',\n",
       " '$cthr',\n",
       " 'spot.',\n",
       " '@johnny_greenjeans',\n",
       " '$ecr',\n",
       " '$mjog',\n",
       " 'forecast',\n",
       " 'digit',\n",
       " 'rockwell',\n",
       " 'dubai.',\n",
       " 'wal-mart',\n",
       " 'csnider',\n",
       " 'incy,',\n",
       " '$clvs',\n",
       " 'telling',\n",
       " 'res.',\n",
       " 'choice',\n",
       " 'http://preciousmetalwatch.com/john-kaiser-why-the-gold-price-could-hit--in-the-next',\n",
       " 'service.',\n",
       " 'creasy',\n",
       " 'science',\n",
       " '$neos',\n",
       " '$eem',\n",
       " 'gaming',\n",
       " 'prob',\n",
       " '$slb',\n",
       " 'feb-mar',\n",
       " 'dupixent...they',\n",
       " 'anything',\n",
       " 'nov.',\n",
       " 'here!??',\n",
       " 'hawk!',\n",
       " '$trx.x',\n",
       " 'theater',\n",
       " 'pleased.',\n",
       " 'person',\n",
       " 'https://www.youtube.com/watch?v=vgfadvlio',\n",
       " 'pathetic',\n",
       " 'high,',\n",
       " 'fwd',\n",
       " 'dec.',\n",
       " 'finviz.com',\n",
       " 'cap,',\n",
       " ',,told',\n",
       " '////en/us-auto-parts-co-founder-and-former-ceo-mehran-nia-recommends-the-board-explore-a-sale-to-maximize-value.html',\n",
       " 'rocket',\n",
       " 'wednesday.',\n",
       " 'thing.',\n",
       " 'deserves',\n",
       " 'seemed',\n",
       " 'park',\n",
       " 'https://www.quora.com/do-you-agree-with-dave-chapman-that-bitcoin-will-be-at---usd-by',\n",
       " 'ridiculous.',\n",
       " 'burglar&#;s',\n",
       " 'vocal',\n",
       " 'panic,',\n",
       " 'philips',\n",
       " 'relentless',\n",
       " 'count',\n",
       " 'believe',\n",
       " '$flks',\n",
       " '(cont)',\n",
       " 'woow!',\n",
       " 'surpass',\n",
       " 'crossed,',\n",
       " 'pulling',\n",
       " 'binance.',\n",
       " 'ecstatic',\n",
       " '&lt;&gt;',\n",
       " 'equity,the',\n",
       " 'vol',\n",
       " 'max....its',\n",
       " 'https://seekingalpha.com/article/-signets--percent-plunge-',\n",
       " '$macro',\n",
       " '$hrc',\n",
       " 'thoughts',\n",
       " 'terrify',\n",
       " 'calculating',\n",
       " '$ehth',\n",
       " 'slow',\n",
       " '$aary',\n",
       " '@reformedtrader',\n",
       " 'buy/selling',\n",
       " 'shame',\n",
       " 'http://stks.co/tnl',\n",
       " 'october',\n",
       " 'after,',\n",
       " 'freddie',\n",
       " '...ends',\n",
       " 'absolutely',\n",
       " 'missing',\n",
       " 'die...',\n",
       " '$vale',\n",
       " '#gdxj',\n",
       " 'ceo&#;s!',\n",
       " 'https://seekingalpha.com/article/-study-finds-laparoscopic-surgical-robots-offer-clinical-benefit-will-hurt-transenterix-sales',\n",
       " 'betsy',\n",
       " 'litecoin.',\n",
       " 'either',\n",
       " 'effort',\n",
       " 'sears',\n",
       " '$erj',\n",
       " '$wll',\n",
       " 'path',\n",
       " 'stays',\n",
       " 'projections',\n",
       " 'bears,',\n",
       " 'another,',\n",
       " '$nwl',\n",
       " 'mkt',\n",
       " 'guided',\n",
       " 'gss',\n",
       " 'shock!',\n",
       " 'retest',\n",
       " 'hikes',\n",
       " 'dude',\n",
       " 'porto',\n",
       " 'becoming',\n",
       " 'focus.',\n",
       " 'let&#;s',\n",
       " 'nicely',\n",
       " 'see.',\n",
       " 'makes.',\n",
       " 'dip?',\n",
       " 'trump',\n",
       " '$sien',\n",
       " '@natesnotes',\n",
       " 'cracks',\n",
       " '@mheadroom',\n",
       " 'levy',\n",
       " '(longs)',\n",
       " 'https://www.marketwatch.com/story/roku-short-sellers-getting-killed-as-stock-soars---',\n",
       " 'whereas',\n",
       " 'hold)',\n",
       " 'yet.',\n",
       " 'sucking',\n",
       " 'bombardier.',\n",
       " 'gds?',\n",
       " '@louriv',\n",
       " 'results.here',\n",
       " 'sliding',\n",
       " 'bangarang!!!!',\n",
       " 'mood',\n",
       " 'present..lol',\n",
       " 'faded',\n",
       " 'qtr...',\n",
       " '$edz',\n",
       " 'teck...i',\n",
       " 'price:',\n",
       " 'sleep',\n",
       " 'accumulated',\n",
       " 'changing',\n",
       " 'patent&#;s',\n",
       " '$tsg',\n",
       " 'entertainment.',\n",
       " 'post',\n",
       " 'monopoly',\n",
       " 'jose',\n",
       " 'https://clinicaltrials.gov/ct/show/nct?term=incagn&amp;rank=',\n",
       " 'looks',\n",
       " 'soon!!',\n",
       " 'equities:',\n",
       " 'equal',\n",
       " 'alrighty',\n",
       " 'let',\n",
       " 'title',\n",
       " 'week,',\n",
       " 'cibc...lol',\n",
       " 'investors!!',\n",
       " 'noted,',\n",
       " '@scotand',\n",
       " 'makings',\n",
       " 'rise',\n",
       " '$paas',\n",
       " 'acc',\n",
       " 'effective',\n",
       " 'vetr!',\n",
       " '$nzdcad',\n",
       " 'folks......this',\n",
       " 'earnings.',\n",
       " '$mplx',\n",
       " 'launching',\n",
       " '$enph',\n",
       " 'analysts?',\n",
       " 'random',\n",
       " 'was,',\n",
       " 'market...',\n",
       " 'quality&quot;',\n",
       " 'etn.',\n",
       " 'hell...will',\n",
       " 'slash',\n",
       " '$kro',\n",
       " 'shipper',\n",
       " 'burst.',\n",
       " 'qualification',\n",
       " 'anticipates',\n",
       " 'omisego',\n",
       " 'breakout.',\n",
       " 'hyped',\n",
       " 'tuesday!',\n",
       " 'end,',\n",
       " '$sage',\n",
       " '@frmaza',\n",
       " 'rel.',\n",
       " 'i&#;ll',\n",
       " '$ifon',\n",
       " 'sales.',\n",
       " '.golong',\n",
       " '$mga',\n",
       " 'drop.',\n",
       " 'moment',\n",
       " 'factores',\n",
       " 'res',\n",
       " 'prts',\n",
       " 'site',\n",
       " 'report...could',\n",
       " 'massive',\n",
       " 'agribusiness',\n",
       " 'pivotal',\n",
       " 'smaller',\n",
       " 'http://stks.co/cgp',\n",
       " '$eth',\n",
       " 'prepayment!',\n",
       " '&#;&#;going',\n",
       " 'upfront',\n",
       " 'enters',\n",
       " 'well,',\n",
       " '$mik',\n",
       " 'vwap',\n",
       " 'alibaba:',\n",
       " 'present.....',\n",
       " 'art.',\n",
       " 'below',\n",
       " '$bch.x',\n",
       " 'tightening,',\n",
       " 'fitbit!!!!',\n",
       " '$soupq',\n",
       " '$team',\n",
       " 'bio..',\n",
       " 'erinn...looks',\n",
       " 'commences,',\n",
       " 'claims',\n",
       " '.,close',\n",
       " 'biopharma',\n",
       " '-now',\n",
       " '$btcd.x',\n",
       " 'based',\n",
       " 'livingston',\n",
       " 'ever',\n",
       " 'qudian.',\n",
       " 'pal',\n",
       " 'download',\n",
       " 'eggs',\n",
       " 'sold.',\n",
       " 'wsj.',\n",
       " 'agen:)',\n",
       " 'lookn',\n",
       " '-institutes',\n",
       " 'time&#;s',\n",
       " 'fractal.',\n",
       " '$cost.',\n",
       " 'apple).',\n",
       " 'followers',\n",
       " '$cveo',\n",
       " 'environment',\n",
       " 'faster',\n",
       " 'hundredfold!',\n",
       " 'vln,',\n",
       " 'breakeven',\n",
       " 'sure..',\n",
       " 'unblocked',\n",
       " 'more!',\n",
       " '$cpg.to',\n",
       " 'value.',\n",
       " 'quant',\n",
       " 'ripped',\n",
       " 'play...its',\n",
       " 'facts',\n",
       " 'propping',\n",
       " 'out@.',\n",
       " 'then',\n",
       " 'approval.',\n",
       " '$relv',\n",
       " 'mcfly,',\n",
       " 'drop..',\n",
       " 'ice',\n",
       " 'trend',\n",
       " 'pattern/',\n",
       " 'month;',\n",
       " 'ceo',\n",
       " 'shorters,',\n",
       " '$stz',\n",
       " 'steele...',\n",
       " 'documentary',\n",
       " '#chart',\n",
       " '$mygn',\n",
       " 'chart?',\n",
       " 'fda/cdc',\n",
       " '$gbt',\n",
       " '$uec',\n",
       " 'best!',\n",
       " 'trending-pback',\n",
       " 'discretionary',\n",
       " 'fang&#;',\n",
       " 'http://stockmillionaires.com/swing-trade-watchlist--cycc/',\n",
       " 'everywhere!',\n",
       " 'wasnt',\n",
       " 'units',\n",
       " 'macd',\n",
       " 'ctlt',\n",
       " '$cmg',\n",
       " 'off...looking',\n",
       " 'musk',\n",
       " 'lolololol.',\n",
       " 'play)',\n",
       " 'citi',\n",
       " 'bath',\n",
       " 'cantor',\n",
       " 'fashion',\n",
       " 'days...',\n",
       " 'asic)=+$,,.',\n",
       " 'squeeze...lets',\n",
       " 'sheet',\n",
       " 'icos',\n",
       " 'starting.',\n",
       " '$memp',\n",
       " 'http://www.swingstocktraders.com/performance.html',\n",
       " '@beachbumsky',\n",
       " 'moon',\n",
       " 'est-...',\n",
       " 'reclaims',\n",
       " 'buy',\n",
       " 'uncertainty',\n",
       " '$vlo.',\n",
       " 'bottle',\n",
       " 'assets',\n",
       " 'https://www.youtube.com/watch?v=qnrrhjqovj',\n",
       " 'openning,',\n",
       " 'fully',\n",
       " '$basi',\n",
       " 'roll',\n",
       " 'nice...',\n",
       " 'taken',\n",
       " 'day',\n",
       " 'amp;min',\n",
       " 'stoch',\n",
       " 'given',\n",
       " '$plg',\n",
       " 'ipo.',\n",
       " '$usdjpy',\n",
       " 'ers',\n",
       " 'longer,',\n",
       " 'https://investoralmanac.com////baron-energy-and-resources',\n",
       " '$txn',\n",
       " 'ico',\n",
       " 'you!',\n",
       " '$gst',\n",
       " '$qpwr',\n",
       " '$vlgea',\n",
       " 'bln',\n",
       " 'exceeding',\n",
       " 'discrete',\n",
       " 'multinational',\n",
       " '$vbiv',\n",
       " 'psoriasis.',\n",
       " '$bit.x',\n",
       " 'the',\n",
       " 'met',\n",
       " 'entered',\n",
       " '#boolish',\n",
       " 'themselves:',\n",
       " '$pulm',\n",
       " 'mins',\n",
       " 'grab',\n",
       " 'return',\n",
       " 'great!',\n",
       " 'throwing',\n",
       " 'sovereign',\n",
       " 'smash.',\n",
       " 'filings',\n",
       " 'gonna',\n",
       " 'wow,',\n",
       " 'imminently',\n",
       " 'brzu',\n",
       " 'explanation...',\n",
       " 'but.....',\n",
       " 'https://www.youtube.com/watch?v=dbxixxikw',\n",
       " 'featuring',\n",
       " 'rotation,',\n",
       " 'letter-adp-chipotle-fannie-and-freddie-herbalife-short-mondelez/',\n",
       " '@investor',\n",
       " 'country,',\n",
       " 'solutions',\n",
       " 'gadot.',\n",
       " 'sell-',\n",
       " 'buddy.',\n",
       " 'pulls',\n",
       " '$bkhm',\n",
       " 'trucks,',\n",
       " 'premarket.',\n",
       " 'free',\n",
       " '$cnd',\n",
       " '$tlra',\n",
       " 'dollers',\n",
       " 'ordere',\n",
       " '$aph.ca',\n",
       " ...]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using model to get embeddingss for these words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.wv[low]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13126, 100)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing these unqique words in a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {k: v for v, k in enumerate(low)}\n",
    "label_dict['<num>'] = len(label_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding <num\\> back in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13126"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict['<num>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding filler word to keep all tweets the same length. Then replacing all words with their dictionary equivalent. This is for tenssorflows matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "bufferIndex = len(label_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "modifiedText = [[label_dict[word] for word in text.split()]for text in stripped]\n",
    "maxLen = max(map(len, modifiedText))\n",
    "for item in modifiedText:                # for each item in the list\n",
    "    while len(item) < maxLen:            # while the item length is smaller than maxLen\n",
    "        item.append(bufferIndex) \n",
    "numpyInp = np.asarray(modifiedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4381, 13126, 12330, ..., 13127, 13127, 13127],\n",
       "       [ 5569, 12353,  6595, ..., 13127, 13127, 13127],\n",
       "       [ 5898,  7543,  6293, ..., 13127, 13127, 13127],\n",
       "       ...,\n",
       "       [ 3457,  7809, 10988, ..., 13127, 13127, 13127],\n",
       "       [ 4890,  1276,  9428, ..., 13127, 13127, 13127],\n",
       "       [13126,  4890,  1276, ..., 13127, 13127, 13127]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpyInp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in unique embeddings for <num\\> and filler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = np.vstack((embed, np.zeros(100)+20, np.zeros(100)+25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13128, 100)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the embedding matrix for any input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = tf.nn.embedding_lookup(embed, numpyInp[2:55], partition_strategy='mod', name=None)\n",
    "embedded_chars_expanded = tf.expand_dims(embedding, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x = embedding.eval()\n",
    "    b = embedded_chars_expanded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 26, 100)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does enumerate do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(1, 3)\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "filter_sizes = [0,3,4]\n",
    "for i in enumerate(filter_sizes):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failed attempt using predefined filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 4 but is rank 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [53,26,100,1], [4].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be rank 4 but is rank 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [53,26,100,1], [4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-370-a13fd168ecf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 strides=1, padding='SAME') '''\n\u001b[0;32m      6\u001b[0m \u001b[0mfilter1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded_chars_expanded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m    957\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1792\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be rank 4 but is rank 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [53,26,100,1], [4]."
     ]
    }
   ],
   "source": [
    "'''WINDOW_SIZE = 100\n",
    "STRIDE = int(WINDOW_SIZE/2)\n",
    "#embedding = tf.reshape(embedding, [53,1,26,100])\n",
    "#conv = tf.layers.conv2d(embedding, 2, [2,WINDOW_SIZE], \n",
    "#               strides=1, padding='SAME') \n",
    "filter1 = np.array([1,2,100]).astype(np.float64)\n",
    "conv = tf.nn.conv2d(embedded_chars_expanded, [1,2,100,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "conv = tf.nn.relu(conv)   \n",
    "words = tf.squeeze(conv, [2]) '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size = 2 \n",
    "embedding_size = 100\n",
    "num_filters = 2\n",
    "filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name='W')\n",
    "b = tf.Variable(tf.constant(0.1, shape=[num_filters]))\n",
    "conv = tf.nn.conv2d(\n",
    "    embedded_chars_expanded,\n",
    "    tf.cast(W,tf.float64),\n",
    "    strides=[1, 1, 1, 1],\n",
    "    padding='VALID',\n",
    "    name='conv')\n",
    "conv = tf.nn.relu(conv)   \n",
    "words = tf.squeeze(conv, [2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
