{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>idx</th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>target_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98221616</td>\n",
       "      <td>4976</td>\n",
       "      <td>$ARNA APD334 for Amyotrophic Lateral Sclerosis...</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82321187</td>\n",
       "      <td>9839</td>\n",
       "      <td>$OCLR Noob investor that i am, put a 7.38 stop...</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>stop loss</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103328840</td>\n",
       "      <td>1455</td>\n",
       "      <td>$ES_F $SPY Bias-2 bearish and the DLT-1 DRR ar...</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104840294</td>\n",
       "      <td>1111</td>\n",
       "      <td>$TMUS its acquisition of Layer3 TV The purchas...</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>Product Number</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69935467</td>\n",
       "      <td>2373</td>\n",
       "      <td>$TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>relative</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69935467</td>\n",
       "      <td>2373</td>\n",
       "      <td>$TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69935467</td>\n",
       "      <td>2373</td>\n",
       "      <td>$TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>forecast</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94249158</td>\n",
       "      <td>1372</td>\n",
       "      <td>$SEED L2 Capital deal is real savvy. It takes ...</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>date</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100979260</td>\n",
       "      <td>505</td>\n",
       "      <td>$BTE $BTE.CA $MEG.CA $CPG $CPG.CA $CJ.CA - 4th...</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>date</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100775772</td>\n",
       "      <td>1210</td>\n",
       "      <td>$WRN My fav $WRN pattern on my watchlist for 1...</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>date</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   idx                                              tweet  \\\n",
       "0   98221616  4976  $ARNA APD334 for Amyotrophic Lateral Sclerosis...   \n",
       "1   82321187  9839  $OCLR Noob investor that i am, put a 7.38 stop...   \n",
       "2  103328840  1455  $ES_F $SPY Bias-2 bearish and the DLT-1 DRR ar...   \n",
       "3  104840294  1111  $TMUS its acquisition of Layer3 TV The purchas...   \n",
       "4   69935467  2373  $TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...   \n",
       "5   69935467  2373  $TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...   \n",
       "6   69935467  2373  $TWTR ^Buy  $WSTL 68c up 14%  4 time avg vol. ...   \n",
       "7   94249158  1372  $SEED L2 Capital deal is real savvy. It takes ...   \n",
       "8  100979260   505  $BTE $BTE.CA $MEG.CA $CPG $CPG.CA $CJ.CA - 4th...   \n",
       "9  100775772  1210  $WRN My fav $WRN pattern on my watchlist for 1...   \n",
       "\n",
       "         category     subcategory target_num  \n",
       "0  Product Number  Product Number        334  \n",
       "1        Monetary       stop loss       7.38  \n",
       "2  Product Number  Product Number          1  \n",
       "3  Product Number  Product Number          5  \n",
       "4      Percentage        relative         14  \n",
       "5        Quantity        Quantity          4  \n",
       "6        Monetary        forecast          5  \n",
       "7        Temporal            date         33  \n",
       "8        Temporal            date          4  \n",
       "9        Temporal            date         11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('finnum/train.csv')\n",
    "x = df1.index\n",
    "df2 = pd.read_csv('finnum/dev.csv')\n",
    "df = pd.concat([df1,df2], ignore_index = True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make new column for encoding categories as numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cat_num'] = df['category'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing tweets by lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lower'] = [x.lower() for x in df.tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    $arna apd334 for amyotrophic lateral sclerosis...\n",
       "1    $oclr noob investor that i am, put a 7.38 stop...\n",
       "2    $es_f $spy bias-2 bearish and the dlt-1 drr ar...\n",
       "3    $tmus its acquisition of layer3 tv the purchas...\n",
       "4    $twtr ^buy  $wstl 68c up 14%  4 time avg vol. ...\n",
       "Name: lower, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lower'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing target with <num\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def flagNum(x):\n",
    "    text = x.lower\n",
    "    outNum = str(x.target_num)\n",
    "    text_out = re.sub(r'(?<=\\D)'+outNum+'(?=\\D)', ' <num> ', text)\n",
    "    #text_out = text.replace('\\D('+outNum+')\\D', ' <num> ')\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying to training, making this into a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mod'] = df.apply(lambda x: flagNum(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    $arna apd <num>  for amyotrophic lateral scler...\n",
       "1    $oclr noob investor that i am, put a  <num>  s...\n",
       "2    $es_f $spy bias-2 bearish and the dlt- <num>  ...\n",
       "3    $tmus its acquisition of layer3 tv the purchas...\n",
       "4    $twtr ^buy  $wstl 68c up  <num> %  4 time avg ...\n",
       "Name: mod, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mod'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out numbers and words less than 3 characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def textPuncandNum(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    text = text.split()\n",
    "    text = [word for word in text if len(word.translate(table))>2]\n",
    "    return ' '.join(text)\n",
    "stripped = [textPuncandNum(text) for text in df['mod']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = [x.split() for x in stripped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contraction(text):\n",
    "    contraction_patterns = [ (r'won\\'t', 'will not'), (r'can\\'t', 'can not'), (r'i\\'m', 'i am'), (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "                         (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'), (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), (r'dont', 'do not'), (r'wont', 'will not') ]\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
    "    for (pattern, repl) in patterns:\n",
    "        (text, count) = re.subn(pattern, repl, text)\n",
    "    return text\n",
    "def replace_links(text, filler=' '):\n",
    "        text = re.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*',\n",
    "                      filler, text).strip()\n",
    "        return text\n",
    "def remove_numbers(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "def cleanText(text):\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = replace_contraction(text)\n",
    "    text = replace_links(text, \"link\")\n",
    "    text = remove_numbers(text)\n",
    "    text = re.sub(r'[,!%^&*)(|\";:.?\\'\\\\}{]',\"\",text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df[\"mod\"].apply(cleanText)\n",
    "max_length = max(len(lst.split()) for lst in words)\n",
    "tokens_length = np.asarray([len(x.split()) for x in words])\n",
    "t_pad = np.asarray([lst.split() + [''] * (max_length - len(lst.split())) for lst in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0418 12:11:24.174127  1708 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\justi\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 12:11:25.503266  1708 deprecation.py:323] From C:\\Users\\justi\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "def ELMoEmbedding(x,y):\n",
    "    return elmo(inputs = {\"tokens\": tf.squeeze(tf.cast(x, tf.string)), \"sequence_len\":tf.cast(y, tf.int32)}, signature=\"tokens\", as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the embedding matrix for any input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainInp = t_pad[x, :]\n",
    "valInp = t_pad[len(x):, :]\n",
    "\n",
    "t_len = tokens_length[x]\n",
    "v_len = tokens_length[len(x):]\n",
    "\n",
    "labels = pd.get_dummies(df['cat_num'][x])\n",
    "labels2 = pd.get_dummies(df['cat_num'][len(x):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching and creating iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (trainInp, t_len, labels)\n",
    "val = (valInp, v_len, labels2)\n",
    "\n",
    "# create training Dataset and batch it\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "train_data = train_data.shuffle(10000) # if you want to shuffle your data\n",
    "train_data = train_data.batch(batch_size)\n",
    "\n",
    "# create validation Dataset and batch it\n",
    "val_data = tf.data.Dataset.from_tensor_slices(val)\n",
    "val_data = val_data.shuffle(10000) # if you want to shuffle your data\n",
    "val_data = val_data.batch(batch_size)\n",
    "\n",
    "# create one iterator and initialize it with different datasets\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types, \n",
    "                                           train_data.output_shapes)\n",
    "txt, length, label = iterator.get_next()\n",
    "\n",
    "train_init = iterator.make_initializer(train_data)\n",
    "val_init = iterator.make_initializer(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0418 12:11:27.929896  1708 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "elmos = ELMoEmbedding(txt, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 500\n",
    "n_neurons2 = 100\n",
    "n_outputs = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-5bab1b968b7f>:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 12:11:28.034616  1708 deprecation.py:323] From <ipython-input-21-5bab1b968b7f>:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-5bab1b968b7f>:3: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 12:11:28.044214  1708 deprecation.py:323] From <ipython-input-21-5bab1b968b7f>:3: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\justi\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 12:11:28.181537  1708 deprecation.py:506] From C:\\Users\\justi\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "basic_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)\n",
    "cell = tf.nn.rnn_cell.DropoutWrapper(basic_cell, output_keep_prob=0.6)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, elmos, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 500) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-a82746380ddf>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 12:11:28.253345  1708 deprecation.py:323] From <ipython-input-23-a82746380ddf>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-a82746380ddf>:3: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 12:11:28.287255  1708 deprecation.py:323] From <ipython-input-23-a82746380ddf>:3: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-a82746380ddf>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 12:11:28.312187  1708 deprecation.py:323] From <ipython-input-23-a82746380ddf>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "dense = tf.layers.dense(states[0], n_neurons2)\n",
    "dropout = tf.layers.dropout(dense, 0.5)\n",
    "logits = tf.layers.dense(dropout, n_outputs)\n",
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=label,logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.cast(logits, tf.float32)\n",
    "label = tf.cast(label, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct = tf.nn.in_top_k(logits, label, 1)\n",
    "correct = tf.equal(tf.argmax(logits, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 1.368954762958345\n",
      "Accuracy 0: 0.5019940476190476\n",
      "Average val loss epoch 0: 1.2068225145339966\n",
      "Val_Accuracy 0: 0.5723958333333333\n",
      "Average loss epoch 1: 0.9180943307422457\n",
      "Accuracy 1: 0.677625\n",
      "Average val loss epoch 1: 0.790621226032575\n",
      "Val_Accuracy 1: 0.7205729166666667\n",
      "Average loss epoch 2: 0.5465610231672015\n",
      "Accuracy 2: 0.810952380952381\n",
      "Average val loss epoch 2: 0.5973976105451584\n",
      "Val_Accuracy 2: 0.7997395833333334\n",
      "Average loss epoch 3: 0.32970965391113644\n",
      "Accuracy 3: 0.8889047619047619\n",
      "Average val loss epoch 3: 0.6637147963047028\n",
      "Val_Accuracy 3: 0.8143229166666667\n",
      "Average loss epoch 4: 0.2076866898508299\n",
      "Accuracy 4: 0.9336130952380952\n",
      "Average val loss epoch 4: 0.7145894144972166\n",
      "Val_Accuracy 4: 0.8151041666666666\n",
      "Average loss epoch 5: 0.1336665708039488\n",
      "Accuracy 5: 0.9569107142857143\n",
      "Average val loss epoch 5: 0.7508332033952078\n",
      "Val_Accuracy 5: 0.8080729166666667\n",
      "Average loss epoch 6: 0.08701327966437453\n",
      "Accuracy 6: 0.9743630952380953\n",
      "Average val loss epoch 6: 0.805382564663887\n",
      "Val_Accuracy 6: 0.8268229166666666\n",
      "Average loss epoch 7: 0.07271310934087351\n",
      "Accuracy 7: 0.9789761904761906\n",
      "Average val loss epoch 7: 0.7038938204447428\n",
      "Val_Accuracy 7: 0.8489583333333334\n",
      "Average loss epoch 8: 0.05095819375433382\n",
      "Accuracy 8: 0.984077380952381\n",
      "Average val loss epoch 8: 0.8094289898872375\n",
      "Val_Accuracy 8: 0.8380208333333333\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # train the model n_epochs times\n",
    "\n",
    "    for i in range(n_epochs): \n",
    "        \n",
    "        sess.run(train_init)# drawing samples from train_data\n",
    "        total_loss = 0\n",
    "        total_right = 0\n",
    "        n_batches = 0\n",
    "        totalright = 0\n",
    "        totalvalright = 0\n",
    "        nvalbatches = 0\n",
    "        totalvalloss = 0\n",
    "        try:\n",
    "            while True:\n",
    "                #summary,acc,_, l = sess.run([summary_op,accuracy,optimizer, loss]) #use with scalar summary\n",
    "                acc,_, l = sess.run([accuracy, training_op, loss])                \n",
    "                total_loss += l\n",
    "                total_right += acc\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        sess.run(val_init)\n",
    "        try:\n",
    "            while True:\n",
    "                accval,valloss = sess.run([accuracy, loss])\n",
    "                totalvalright += accval\n",
    "                nvalbatches += 1\n",
    "                totalvalloss += valloss\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "        print('Accuracy {0}: {1}'.format(i, total_right/n_batches))    \n",
    "        print('Average val loss epoch {0}: {1}'.format(i, totalvalloss/nvalbatches))\n",
    "        print('Val_Accuracy {0}: {1}'.format(i, totalvalright/nvalbatches)) \n",
    "    #prediction = sess.run(preds, feed_dict={txt: valInp})\n",
    "    #prediction = np.asarray(prediction)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
